Got it! I'll remove any mention of **SemEval-2025** and keep the project as a general **hallucination detection in multimodal summarization** task. Here‚Äôs a refined version without SemEval references:  

---

### **üçÑ Mu-SHROOM: Hallucination Detection in Multimodal Summarization**  

## **Overview**  
**Mu-SHROOM** is a research-driven project focusing on **hallucination detection in AI-generated multimodal summaries**. The objective is to identify hallucinated content‚Äîinformation that is not factually grounded in the provided source‚Äîand enhance the reliability of AI summarization systems.  

This project explores **natural language processing (NLP) and multimodal learning** to mitigate hallucinations in generated summaries.  

---

## **Problem Statement**  
AI-generated summaries can introduce **misleading or factually incorrect information**, reducing their trustworthiness. This project aims to:  
- Develop techniques to **detect hallucinated content** in multimodal summaries.  
- Improve the **factual consistency** of summarization models.  

---

## **üìÅ Dataset**  
The dataset consists of **multimodal content**, where textual summaries are paired with additional contextual information. It includes:  
- **Unlabeled Training Data**  
- **Validation Set**  
- **Sample Data for Experimentation**  
- **Unlabeled Test Data**  
- **Labeled Test Set for Evaluation**  

*Note:* Due to confidentiality, dataset specifics are not disclosed publicly.  

---

## **Tech Stack**  
- **Languages**: Python  
- **Libraries/Frameworks**:  
  - `pandas`, `numpy` ‚Äì Data manipulation  
  - `scikit-learn` ‚Äì Classical ML models  
  - `transformers` ‚Äì Pre-trained models (BERT, etc.)  
  - `matplotlib`, `seaborn` ‚Äì Data visualization  
  - `torch` ‚Äì Deep learning framework  
- **Development Environment**: VS Code  
- **Platforms**: Kaggle for experiments, GitHub for version control  

---

## **Approach**  
1. **Data Preprocessing**  
   - Text cleaning, tokenization  
   - Handling multimodal inputs  

2. **Exploratory Data Analysis (EDA)**  
   - Understanding data distribution  
   - Identifying hallucination patterns  

3. **Modeling**  
   - Classical ML models for baseline  
   - Transformer-based architectures for hallucination detection  

4. **Evaluation**  
   - Metrics: F1-Score, Precision, Recall  
   - Comparative analysis of different models  

---

## **Results**  
*(To be updated as experiments progress)*  
- Baseline accuracy: *TBD*  
- Improved F1-Score: *TBD*  

---

## **Future Work**  
- Integrate **vision-language models** for better multimodal understanding  
- Explore **explainable AI (XAI)** for model interpretability  
- Optimize for real-world applications in **content verification**  

---

## **Contact**  
**Megha Gasti**  
üì¨ *[meghagasti969@gmail.com]*  

---
