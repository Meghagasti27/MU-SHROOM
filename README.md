### **üçÑ Mu-SHROOM: Hallucination Detection in Multimodal Summarization**  

## **Overview**  
**Mu-SHROOM** is a research-driven project focusing on **hallucination detection in AI-generated multimodal summaries**. The objective is to identify hallucinated content‚Äîinformation that is not factually grounded in the provided source‚Äîand enhance the reliability of AI summarization systems.  

This project integrates **Machine Learning (ML), Deep Learning (DL) with Transformers, and Explainability (XAI)** to mitigate hallucinations in generated summaries.  

---

## **Problem Statement**  
AI-generated summaries can introduce **misleading or factually incorrect information**, reducing their trustworthiness. This project aims to:  
- Develop techniques to **detect hallucinated content** in multimodal summaries.  
- Improve the **factual consistency** of summarization models.  
- Enhance model interpretability using **Explainable AI (XAI)**.  

---

## **üìÅ Dataset**  
The dataset consists of **multimodal content**, where textual summaries are paired with additional contextual information. It includes:  
- **Unlabeled Training Data**  
- **Validation Set**  
- **Sample Data for Experimentation**  
- **Unlabeled Test Data**  
- **Labeled Test Set for Evaluation**  

*Note:* Due to confidentiality, dataset specifics are not disclosed publicly.  

---

## **Tech Stack**  
- **Languages**: Python  
- **Libraries/Frameworks**:  
  - `pandas`, `numpy` ‚Äì Data manipulation  
  - `scikit-learn` ‚Äì Classical ML models  
  - `transformers` (T5, BERT) ‚Äì Pre-trained models  
  - `matplotlib`, `seaborn` ‚Äì Data visualization  
  - `torch`, `tensorflow` ‚Äì Deep learning frameworks  
  - `SHAP`, `LIME` ‚Äì Explainability tools  
- **Development Environment**: VS Code  
- **Platforms**: Kaggle for experiments, GitHub for version control  

---

## **Approach**  
1. **Data Preprocessing**  
   - Text cleaning, tokenization  
   - Handling multimodal inputs  

2. **Exploratory Data Analysis (EDA)**  
   - Understanding data distribution  
   - Identifying hallucination patterns  

3. **Modeling**  
   - **Baseline Models (ML):** SVM, Na√Øve Bayes, Random Forest  
   - **Deep Learning Models (DL):** Transformer-based architectures (T5, BERT)  
   - **Explainability (XAI):** SHAP, LIME for feature importance analysis  

4. **Evaluation**  
   - Metrics: F1-Score, Precision, Recall  
   - Comparative analysis of ML vs. DL models  

5. **Deployment (Optional)**  
   - Streamlit app for real-world usability  

---

## **Results**  
*(To be updated as experiments progress)*  
- Baseline accuracy: *TBD*  
- Improved F1-Score: *TBD*  

---

## **Future Work**  
- Integrate **vision-language models** for better multimodal understanding  
- Optimize for real-world applications in **content verification**  

---

## **Contact**  
**Megha Gasti**  
üì¨ *[meghagasti969@gmail.com]*

