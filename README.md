# üçÑ Mu-SHROOM: Hallucination Detection in Multimodal Summarization

##  Overview
**Mu-SHROOM** is my solo contribution to the **SemEval-2025 Task-3**, focusing on **Hallucination Detection in Multimodal Summarization**. The goal is to develop models that can effectively identify hallucinated content‚Äîinformation not grounded in the provided source‚Äîin multimodal summaries.

This project explores natural language processing (NLP) techniques combined with multimodal data handling to detect and reduce hallucinations in AI-generated summaries.

---

##  Problem Statement
Hallucinations in AI-generated summaries can mislead users by introducing inaccurate or irrelevant information. This project aims to:
- Detect hallucinated content in multimodal summaries.
- Improve the reliability of AI summarization systems.

---

## üìÅ Dataset
The dataset is sourced from the **SemEval-2025 Mu-SHROOM shared task**, which includes:
- **Train Set (Unlabeled)**  
- **Validation Set**  
- **Sample Set**  
- **Test Set (Unlabeled)**  
- **Labeled Test Set**  

*Note:* The data consists of multimodal content, combining textual summaries with additional contextual information.

---

##  Tech Stack
- **Languages**: Python  
- **Libraries/Frameworks**:  
  - `pandas`, `numpy` ‚Äì Data manipulation  
  - `scikit-learn` ‚Äì Classical ML models  
  - `transformers` ‚Äì Pre-trained models (BERT, etc.)  
  - `matplotlib`, `seaborn` ‚Äì Data visualization  
  - `torch` ‚Äì Deep learning framework  
- **IDE**: VS Code  
- **Platform**: Kaggle for experiments and GitHub for version control  

---

##  Approach
1. **Data Preprocessing**  
   - Text cleaning, tokenization  
   - Handling multimodal inputs  

2. **Exploratory Data Analysis (EDA)**  
   - Insights into data distribution  
   - Analyzing hallucination patterns  

3. **Modeling**  
   - Baseline models using classical ML  
   - Fine-tuned Transformer-based models for hallucination detection  

4. **Evaluation**  
   - Metrics: F1-Score, Precision, Recall  
   - Compare models for the best performance  

---

##  Results
*(To be updated once results are available)*  
- Baseline accuracy: *TBD*  
- Improved F1-Score: *TBD*  

---

## Future Work
- Incorporate vision-language models for better multimodal understanding  
- Experiment with explainable AI (XAI) to interpret model decisions  
- Optimize for real-world applications in content verification  

---


##  Contact
**Megha Gasti**  
üì¨ *[meghagasti969@gmail.com]*  
 
